{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9bc983-b9b2-490f-820b-f5942aec4921",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7383676-219d-4714-aa3e-22c50aaef5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from ipynbname import path as nb_path\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "\n",
    "# HTML Cleanup\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from bs4.element import Tag\n",
    "\n",
    "# Json cleanup\n",
    "from difflib import SequenceMatcher\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca5f2c-0d08-492f-ba7b-2c542d53b239",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d7dee0-b9b3-47e6-a9d7-9666ff7b7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import (\n",
    "    CHATBOT_SERVICE_ROOT,\n",
    "    RAW_DATA_DIR,\n",
    "    CLEANED_DATA_DIR, \n",
    "    SITES_DIRS,\n",
    "    URL_MAP_FILENAME,\n",
    "    SITE_ELEMENTS_JSON_FILENAME,\n",
    "    SITES_ELEMENTS_JSON_PATH,\n",
    "    ALLOWED_TAGS,\n",
    "    SIMILAR_TEXT_THRESHOLD\n",
    ")\n",
    "\n",
    "# # Paths\n",
    "\n",
    "# # directory of this script, DO NOT run this file from another dir\n",
    "# SCRIPT_DIR = Path.cwd()\n",
    "\n",
    "# # chatbot service root = one level up\n",
    "# CHATBOT_SERVICE_ROOT = os.path.normpath(os.path.join(SCRIPT_DIR, os.pardir))\n",
    "\n",
    "# RAW_DATA_DIR = os.path.join(CHATBOT_SERVICE_ROOT, 'data', 'raw')\n",
    "# CLEANED_DATA_DIR  = os.path.join(CHATBOT_SERVICE_ROOT, 'data', 'cleaned')\n",
    "\n",
    "# # in original and cleaned dirs\n",
    "# # SITES_DIRS = ['vmi_site', 'sodra_site', 'micenter_site']\n",
    "# SITES_DIRS = ['micenter_site']\n",
    "\n",
    "# # this file is in every site's directory\n",
    "# URL_MAP_FILENAME = 'url_map.json'\n",
    "\n",
    "# # cleaned data json array in each of SITES_DIRS\n",
    "# SITE_ELEMENTS_JSON_FILENAME = \"cleaned_data.json\"\n",
    "\n",
    "# # cleaned data from all htmls, converted to json\n",
    "# SITES_ELEMENTS_JSON_PATH = os.path.join(CLEANED_DATA_DIR, 'sites_elements.json')\n",
    "\n",
    "\n",
    "# # HTML cleaner\n",
    "# ALLOWED_TAGS = {\n",
    "#     *[f\"h{i}\" for i in range(1,7)],\n",
    "#     \"p\", \"ul\", \"ol\", \"li\",\n",
    "#     \"br\"\n",
    "# }\n",
    "\n",
    "\n",
    "# # Json cleaner\n",
    "\n",
    "# # Allows slight rewording, different word endings\n",
    "# SIMILAR_TEXT_THRESHOLD = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c9958-8684-4861-99ac-c84b2039c8d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cleaning HTMLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ed06c-bcf3-4bed-b8e6-b46e3579a91e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### HTML File Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e86694-55d9-4b92-b0d8-1b8dd8bef590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def remove_links(text: str) -> str:\n",
    "        # Removes [anything inside brackets]\n",
    "        return re.sub(r\"\\[[^\\[\\]]*\\]\", \"\", text)\n",
    "\n",
    "def normalize_for_comparison(text: str) -> str:\n",
    "    text_no_links = remove_links(text)\n",
    "    text_cleaned = text_no_links.lower().strip().replace('\\xa0', ' ')\n",
    "    return ' '.join(text_cleaned.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ff816f-6824-41af-8f3b-4e945f8e91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLCleaner:\n",
    "    '''\n",
    "    Cleans single HTML file\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        html_path: str,\n",
    "        config: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        config = config or {}\n",
    "        self.html_path: str = html_path\n",
    "        self.allowed_tags = config.get(\"allowed_tags\", [])\n",
    "        self.debug: bool = config.get(\"debug\", False)\n",
    "        self.indent_for_saving_json = config.get(\"indent_for_saving_json\", 4)\n",
    "        self.SIMILAR_TEXT_THRESHOLD = config.get(\"SIMILAR_TEXT_THRESHOLD\", 0.85)\n",
    "\n",
    "    def load_html(self):\n",
    "        with open(self.html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.soup = BeautifulSoup(f, \"html.parser\")\n",
    "            \n",
    "    def get_raw_html(self) -> BeautifulSoup:\n",
    "        self.load_html()\n",
    "        return self.soup\n",
    "\n",
    "    def clean_html(self) -> BeautifulSoup:\n",
    "        \"\"\"\n",
    "        Remove all tags except given in 'allowed_tags'\n",
    "        Handle <a> only when inside a <p>: inline its text + href.\n",
    "        Remove empty layout <div> but unwrap any <div> that has real text.\n",
    "        \"\"\"\n",
    "        # ensure we have a parsed soup\n",
    "        if not hasattr(self, \"soup\"):\n",
    "            self.load_html()\n",
    "\n",
    "        # First handle all <a> tags\n",
    "        for a in list(self.soup.find_all(\"a\")):\n",
    "            # only keep if anchor is inside a paragraph\n",
    "            if a.find_parent(\"p\") or a.find_parent(\"li\") or a.find_parent(\"ol\") or a.find_parent(\"ul\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                text = a.get_text(strip=False)\n",
    "                if text == \"\":\n",
    "                    a.decompose()\n",
    "                    continue\n",
    "                \n",
    "                # replace <a> with \"text [href]\"\n",
    "                replacement = f\"{text} [{href}]\" if href else text\n",
    "                a.replace_with(NavigableString(replacement))\n",
    "            else:\n",
    "                # drop menu or navigation links\n",
    "                a.decompose()\n",
    "\n",
    "        # Next process all other tags\n",
    "        for tag in list(self.soup.find_all(True)):\n",
    "            # guard against non‐Tags or tags with no name\n",
    "            if not isinstance(tag, Tag) or tag.name is None:\n",
    "                continue            \n",
    "            \n",
    "            name = tag.name.lower()\n",
    "            if name in self.allowed_tags and not tag.get_text(strip=False) and not tag.find_all(\"br\"):\n",
    "                tag.decompose()\n",
    "                continue\n",
    "            if name in self.allowed_tags:\n",
    "                continue\n",
    "\n",
    "            if name == \"div\":\n",
    "                # if there's no user‑visible text, drop it entirely\n",
    "                if not tag.get_text(strip=False):\n",
    "                    tag.decompose()\n",
    "                else:\n",
    "                    # unwrap to keep its children\n",
    "                    tag.unwrap()\n",
    "            else:\n",
    "                # for any other disallowed tag, just unwrap it\n",
    "                tag.unwrap()\n",
    "\n",
    "        return self.soup\n",
    "\n",
    "    def get_clean_soup(self) -> BeautifulSoup:\n",
    "        \"\"\"Load, clean, and return the BeautifulSoup tree in one call.\"\"\"\n",
    "        if not hasattr(self, \"soup\"):\n",
    "            self.load_html()\n",
    "        return self.clean_html()\n",
    "\n",
    "    def convert_list_item_into_clean_text(self, li: Tag) -> str:\n",
    "        # Convert <li> content into clean plain text\n",
    "        return \"• \" + li.get_text(separator=\" \", strip=False)\n",
    "\n",
    "    def convert_br_into_clean_text(self, br: Tag) -> str:\n",
    "        return \"\\n\"\n",
    "\n",
    "    def convert_p_into_clean_text(self, tag: Tag) -> str:\n",
    "        return f\"{tag.get_text(strip=False)}\\n\"\n",
    "    \n",
    "    def convert_header_into_clean_text(self, tag: Tag) -> str:\n",
    "        name = tag.name.lower()\n",
    "        text = tag.get_text(strip=False)\n",
    "        \n",
    "        header_level = int(name[1]) # Assuming that header number is single digit\n",
    "        prefix = \"#\" * header_level\n",
    "        return f\"{prefix} {tag.get_text(strip=True)}\\n\"\n",
    "        \n",
    "    def convert_soup_to_clean_text(self, saved_texts: Optional[List[str]] = None) -> str:\n",
    "        saved_texts = saved_texts if saved_texts is not None else []\n",
    "        clean_soup = self.get_clean_soup()\n",
    "        merged_text = \"\"\n",
    "        \n",
    "        tags = clean_soup.find_all(True)\n",
    "        for tag in tags:\n",
    "            name = tag.name.lower()\n",
    "\n",
    "            # Potential text to be merged\n",
    "            new_text = \"\"\n",
    "            \n",
    "            if name == \"li\":                \n",
    "                new_text = self.convert_list_item_into_clean_text(tag) + \"\\n\"\n",
    "\n",
    "            elif name.startswith(\"h\") and name[1:].isdigit():\n",
    "                new_text = self.convert_header_into_clean_text(tag)\n",
    "\n",
    "            elif name == 'p':\n",
    "                new_text = self.convert_p_into_clean_text(tag)\n",
    "\n",
    "            elif name == 'br':\n",
    "                new_text = self.convert_br_into_clean_text(tag)\n",
    "\n",
    "            if not new_text:\n",
    "                continue\n",
    "\n",
    "            is_new_el_different = True\n",
    "            for saved_text in saved_texts:\n",
    "                normalized_saved = normalize_for_comparison(saved_text)\n",
    "                normalized_new = normalize_for_comparison(new_text)\n",
    "                \n",
    "                if SequenceMatcher(None, normalized_saved, normalized_new).ratio() > self.SIMILAR_TEXT_THRESHOLD:\n",
    "                    is_new_el_different = False\n",
    "                    break\n",
    "            if is_new_el_different:\n",
    "                merged_text += new_text\n",
    "                saved_texts.append(new_text)\n",
    "                            \n",
    "        return merged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3b5dd64-fdca-4465-8093-9f925a67ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gerzem1/PDP/DCIP/migrant-info-platform/backend/chatbot_service/data/cleaned/micenter_site/micenter.lt_en_change-of-employer.json\n",
      "('Toll-free hotline\\n'\n",
      " '0 800 22922 \\n'\n",
      " 'Consultations will not \\n'\n",
      " 'be available on 17 April \\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'If you’re a foreigner working in Lithuania with a residence permit and want '\n",
      " 'to change employers, in most cased you’ll need to get permission '\n",
      " '[https://www.migracija.lt/changing-employer] first. Your new employer will '\n",
      " 'need to send a mediation letter '\n",
      " '[https://www.migracija.lt/app/form-wizard/mediation-letter] to the Migration '\n",
      " 'Department, and you’ll need to submit a request for approval. You can start '\n",
      " 'your new job only after receiving this permission.\\n'\n",
      " '## How to change employer in Lithuania?\\n'\n",
      " 'For Non-Highly Skilled Occupations: If your residence permit isn’t for a '\n",
      " 'high-skilled job [/en/blue-card], you’ll need permission to change your '\n",
      " 'employer. You can apply for this change no sooner than 6 months after your '\n",
      " 'temporary residence permit was issued.\\n'\n",
      " 'Decision Time: The Migration Department will make a decision within 1 '\n",
      " 'month.\\n'\n",
      " 'Validity: The permit is valid for one month after the decision is made. \\n'\n",
      " 'For EU Blue Card Holders in Lithuania - no Migration Department Decision '\n",
      " 'Required:\\n'\n",
      " '• If Employed for Over One Year: If you’ve been working legally in a '\n",
      " 'high-skilled job for over a year, just notify the Migration Department '\n",
      " 'through the MIGRIS system within 7 working days. No additional decision from '\n",
      " 'the Migration Department is needed.\\n'\n",
      " '• Changing Job Function: You don’t need permission to change your job '\n",
      " 'function with the same employer.\\n'\n",
      " 'Requires Migration Department Decision:\\n'\n",
      " '• Within the First Year: If you want to switch employers within the first '\n",
      " 'year of legal employment, you’ll need a decision from the Migration '\n",
      " 'Department\\n'\n",
      " '• After Job Loss: If you end your job within 12 months of your Blue Card’s '\n",
      " 'issue date and want to start a new highly skilled job with another employer '\n",
      " 'within 6 months, you’ll need approval from the Migration Department.\\n'\n",
      " 'Validity: The permit to change your employer or job position is valid for '\n",
      " 'one month after the decision is made.\\n'\n",
      " '## How to Apply for a Permit to Change Employer or Job Position?\\n'\n",
      " '• Your new or current employer (for job function changes) submits a  '\n",
      " 'mediation lette [https://www.migracija.lt/app/form-wizard/mediation-letter] '\n",
      " 'r through MIGRIS.\\n'\n",
      " '• Once you receive the mediation letter number, you can  submit your '\n",
      " 'application  [https://www.migracija.lt/changing-employer] in your personal '\n",
      " 'MIGRIS profile.\\n'\n",
      " 'State Fee '\n",
      " '[https://migracija.lrv.lt/lt/paslaugos/valstybes-rinkliavu-sarasas/leidimai-gyventi-2/]: '\n",
      " '€100 for the application and decision.\\n'\n",
      " 'IMPORTANT: You can only start with your new employer or change job functions '\n",
      " 'with the same employer after you’ve received approval from the Migration '\n",
      " 'Department.\\n'\n",
      " '\\n'\n",
      " 'The International Organization for Migration (IOM) is part of the United '\n",
      " 'Nations System as the leading inter-governmental organization promoting '\n",
      " 'since 1951 humane and orderly migration for the benefit of all, with 175 '\n",
      " 'member states and a presence in over 100 countries. IOM has had a presence '\n",
      " 'in Lithuania since 1998.\\n'\n",
      " 'IOM has established a Migration Information Center in Lithuania that '\n",
      " 'provides information and services to migrants to facilitate their '\n",
      " 'integration.\\n'\n",
      " '0 800 22922 (free line)\\n'\n",
      " '+370 525 14352\\n'\n",
      " 'Jasinskio st. 16, II floor\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[https://www.google.com/maps/dir/54.7157558,25.266244/migration+information+center+lithuania/@54.7019533,25.2448175,14z/data=!3m1!4b1!4m9!4m8!1m1!4e1!1m5!1m1!1s0x46dd952291c16a0d:0x5ab716e3b0066f76!2m2!1d25.259492!2d54.6870158?entry=ttu&g_ep=EgoyMDI0MDkyNC4wIKXMDSoASAFQAw%3D%3D]\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config_html_cleaner = {\n",
    "    \"allowed_tags\": ALLOWED_TAGS,\n",
    "    \"debug\": True,\n",
    "    \"indent_for_saving_json\": 4\n",
    "}\n",
    "\n",
    "# Usage:\n",
    "html_filename = os.path.join(RAW_DATA_DIR, 'micenter_site', 'micenter.lt_en_change-of-employer.html')\n",
    "cleaner = HTMLCleaner(html_filename, config_html_cleaner)\n",
    "# clean_soup = cleaner.clean_html()\n",
    "# print(clean_soup.prettify())\n",
    "# print(cleaner.convert_soup_to_json())\n",
    "# pprint(cleaner.convert_soup_to_json(), width=120)\n",
    "base, _ = os.path.splitext(os.path.join(CLEANED_DATA_DIR, 'micenter_site', 'micenter.lt_en_change-of-employer.html'))\n",
    "saving_path = base + \".json\"\n",
    "print(saving_path)\n",
    "# os.makedirs(os.path.join(CLEANED_DATA_DIR, 'micenter_site'), exist_ok=True) \n",
    "text = cleaner.convert_soup_to_clean_text()\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dd4d8-781d-42bf-997a-f19ff09314d4",
   "metadata": {},
   "source": [
    "#### Cleaning of All HTMLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9be8b-f8a5-4505-9216-f9bb6f3a30a7",
   "metadata": {},
   "source": [
    "## Merging All Data into a Single Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65042cc7-8b4b-46be-bdf8-68bcb535830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_source_entry(text: str = \"\", source: str = \"\") -> dict[str, str]:\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"source\": source\n",
    "    }\n",
    "\n",
    "class AllCleanedSitesData:\n",
    "    \"\"\"\n",
    "    Cleaned data of all scraped sites in the same file.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        sites_dirs: List[str],\n",
    "        config: Dict[str, Any]\n",
    "    ):\n",
    "        if not isinstance(sites_dirs, list):\n",
    "            raise TypeError(\"sites_dirs must be a list of strings.\")\n",
    "        self.sites_dirs: List[str] = sites_dirs\n",
    "\n",
    "        REQUIRED_KEYS: Dict[str, type] = {\n",
    "            \"ALLOWED_TAGS\": (list, set),\n",
    "            \"RAW_DATA_DIR\": str,\n",
    "            \"CLEANED_DATA_DIR\": str,\n",
    "            \"URL_MAP_FILENAME\": str,\n",
    "            \"SITE_ELEMENTS_JSON_FILENAME\": str,\n",
    "            \"SITES_ELEMENTS_JSON_PATH\": str,\n",
    "            \"SIMILAR_TEXT_THRESHOLD\": float\n",
    "        }\n",
    "        \n",
    "        for key, expected_type in REQUIRED_KEYS.items():\n",
    "            if key not in config:\n",
    "                raise ValueError(f\"Missing required config key: {key}\")\n",
    "            if not isinstance(config[key], expected_type):\n",
    "                raise TypeError(\n",
    "                    f\"Config key '{key}' must be of type {expected_type.__name__}, \"\n",
    "                    f\"got {type(config[key]).__name__}\"\n",
    "                )\n",
    "\n",
    "        self.ALLOWED_TAGS = config[\"ALLOWED_TAGS\"]\n",
    "        self.RAW_DATA_DIR = config[\"RAW_DATA_DIR\"]\n",
    "        self.CLEANED_DATA_DIR = config[\"CLEANED_DATA_DIR\"]\n",
    "        self.URL_MAP_FILENAME = config[\"URL_MAP_FILENAME\"]\n",
    "        self.SITE_ELEMENTS_JSON_FILENAME = config[\"SITE_ELEMENTS_JSON_FILENAME\"]\n",
    "        self.SITES_ELEMENTS_JSON_PATH = config[\"SITES_ELEMENTS_JSON_PATH\"]\n",
    "        self.SIMILAR_TEXT_THRESHOLD = config[\"SIMILAR_TEXT_THRESHOLD\"]\n",
    "\n",
    "        self.html_cleaner_config = {\n",
    "            \"allowed_tags\": self.ALLOWED_TAGS,\n",
    "            \"SIMILAR_TEXT_THRESHOLD\": self.SIMILAR_TEXT_THRESHOLD,\n",
    "            \"debug\": config.get(\"debug\", False)\n",
    "        }\n",
    "\n",
    "        self.saved_texts = [] # text chunks from every file\n",
    "\n",
    "    def merge_cleaned_site_jsons(self, site_dir: str, save_site: bool = True) -> List[Dict[str, str]]:\n",
    "        url_map_path = os.path.join(self.RAW_DATA_DIR, site_dir, self.URL_MAP_FILENAME)\n",
    "        with open(url_map_path, 'r', encoding='utf-8') as file:\n",
    "            url_map = json.load(file)\n",
    "\n",
    "        site_elements_in_json = []\n",
    "        total_files = len(url_map)\n",
    "        last_printed_percent = -10  # to ensure 0% prints immediately\n",
    "        print(f\"Processing: {site_dir}\")\n",
    "        \n",
    "        for i, (html_filename, page_link) in enumerate(url_map.items(), start=1):\n",
    "            print(f\"Progressing {html_filename} ({i})\")\n",
    "            percent_complete = int((i / total_files) * 100)\n",
    "            if percent_complete >= last_printed_percent + 10:\n",
    "                print(f\"Progress: {percent_complete}% ({i}/{total_files})\")\n",
    "                last_printed_percent = percent_complete\n",
    "            \n",
    "            path_with_base, extension = os.path.splitext(os.path.join(self.CLEANED_DATA_DIR, site_dir, html_filename))\n",
    "            if extension != \".html\":\n",
    "                continue       \n",
    "            \n",
    "            html_path = os.path.join(self.RAW_DATA_DIR, site_dir, html_filename)\n",
    "            if not os.path.isfile(html_path):\n",
    "                print(f\"Warning: File not found: {html_path}\")\n",
    "                continue\n",
    "            \n",
    "            html_cleaner = HTMLCleaner(html_path=html_path, config=self.html_cleaner_config)\n",
    "            merged_clean_text = html_cleaner.convert_soup_to_clean_text(self.saved_texts)\n",
    "            site_elements_in_json.append(make_text_source_entry(text=merged_clean_text, source=page_link))\n",
    "\n",
    "        if save_site:\n",
    "            os.makedirs(os.path.join(self.CLEANED_DATA_DIR, site_dir), exist_ok=True) \n",
    "            saving_path = os.path.join(self.CLEANED_DATA_DIR, site_dir, self.SITE_ELEMENTS_JSON_FILENAME)\n",
    "            with open(saving_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(site_elements_in_json, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        return site_elements_in_json\n",
    "        \n",
    "    \n",
    "    def convert_sites_data_to_json_list(self, save: bool = True) -> List[Dict[str, str]]:   \n",
    "        \"\"\"\n",
    "        Merges all sites data to single json list\n",
    "        \"\"\"\n",
    "        merged_data = []\n",
    "\n",
    "        for site_dir in self.sites_dirs:\n",
    "            site_data = self.merge_cleaned_site_jsons(site_dir=site_dir)\n",
    "            merged_data.extend(site_data)\n",
    "            print(f\"Processed: {site_dir}\")\n",
    "\n",
    "        if save:\n",
    "            with open(self.SITES_ELEMENTS_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(merged_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0f3976-5e3e-41d9-8dff-a542855c6cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: micenter_site\n",
      "Progressing micenter.lt_en.html (1)\n",
      "Progress: 0% (1/228)\n",
      "Progressing micenter.lt_lt.html (2)\n",
      "Progressing micenter.lt_ru.html (3)\n",
      "Progressing micenter.lt_en_learn-lithuanian.html (4)\n",
      "Progressing micenter.lt_en_about-us.html (5)\n",
      "Progressing micenter.lt_index.html (6)\n",
      "Progressing micenter.lt_en_main-information.html (7)\n",
      "Progressing micenter.lt_en_interesting-facts.html (8)\n",
      "Progressing micenter.lt_en_migration-statistics.html (9)\n",
      "Progressing micenter.lt_en_travel-to-lithuania.html (10)\n",
      "Progressing micenter.lt_en_schengen-visa.html (11)\n",
      "Progressing micenter.lt_en_visa-d.html (12)\n",
      "Progressing micenter.lt_en_temporary-residence-permit.html (13)\n",
      "Progressing micenter.lt_en_blue-card.html (14)\n",
      "Progressing micenter.lt_en_permanent-residence-permit.html (15)\n",
      "Progressing micenter.lt_en_temporary-protection.html (16)\n",
      "Progressing micenter.lt_en_legalization-of-documents.html (17)\n",
      "Progressing micenter.lt_en_job-search.html (18)\n",
      "Progressing micenter.lt_en_working-conditions.html (19)\n",
      "Progressing micenter.lt_en_work-permit.html (20)\n",
      "Progressing micenter.lt_en_change-of-employer.html (21)\n",
      "Progressing micenter.lt_en_starting-a-business.html (22)\n",
      "Progressing micenter.lt_en_violations-of-workers-rights.html (23)\n",
      "Progress: 10% (23/228)\n",
      "Progressing micenter.lt_en_declaration-of-residence.html (24)\n",
      "Progressing micenter.lt_en_rental-accomodation.html (25)\n",
      "Progressing micenter.lt_en_property-purchase.html (26)\n",
      "Progressing micenter.lt_en_mortgage.html (27)\n",
      "Progressing micenter.lt_en_healthcare-system.html (28)\n",
      "Progressing micenter.lt_en_health-insurance.html (29)\n",
      "Progressing micenter.lt_en_doctors.html (30)\n",
      "Progressing micenter.lt_en_clinics-and-hospitals.html (31)\n",
      "Progressing micenter.lt_en_psychological-assistance.html (32)\n",
      "Progressing micenter.lt_en_pre-school-education.html (33)\n",
      "Progressing micenter.lt_en_schools.html (34)\n",
      "Progressing micenter.lt_en_study-in-lithuania.html (35)\n",
      "Progressing micenter.lt_en_recognition-of-foreign-qualifications.html (36)\n",
      "Progressing micenter.lt_en_taxes.html (37)\n",
      "Progressing micenter.lt_en_opening-bank-account.html (38)\n",
      "Progressing micenter.lt_en_loans.html (39)\n",
      "Progressing micenter.lt_en_income-declaration.html (40)\n",
      "Progressing micenter.lt_en_tax-refund.html (41)\n",
      "Progressing micenter.lt_en_arrival-allowance.html (42)\n",
      "Progressing micenter.lt_en_benefits-for-parents.html (43)\n",
      "Progressing micenter.lt_en_shild-benefits.html (44)\n",
      "Progressing micenter.lt_en_social-benefits.html (45)\n",
      "Progressing micenter.lt_en_old-age-pension.html (46)\n",
      "Progress: 20% (46/228)\n",
      "Progressing micenter.lt_en_humanitarian-aid.html (47)\n",
      "Progressing micenter.lt_en_children.html (48)\n",
      "Progressing micenter.lt_en_getting-married.html (49)\n",
      "Progressing micenter.lt_en_divorce.html (50)\n",
      "Progressing micenter.lt_en_dual-citizenship.html (51)\n",
      "Progressing micenter.lt_en_lithuanian-citizenship.html (52)\n",
      "Progressing micenter.lt_en_driving-licence.html (53)\n",
      "Progressing micenter.lt_en_driving-exams.html (54)\n",
      "Progressing micenter.lt_en_vehicle-registration.html (55)\n",
      "Progressing micenter.lt_en_buying-a-vehicle.html (56)\n",
      "Progressing micenter.lt_en_public-transport.html (57)\n",
      "Progressing micenter.lt_en_e-services.html (58)\n",
      "Progressing micenter.lt_en_shopping.html (59)\n",
      "Progressing micenter.lt_en_telecommunications.html (60)\n",
      "Progressing micenter.lt_en_bills.html (61)\n",
      "Progressing micenter.lt_en_what-to-do-in-a-case-of-emergency.html (62)\n",
      "Progressing micenter.lt_en_elections.html (63)\n",
      "Progressing micenter.lt_en_how-to-become-a-local.html (64)\n",
      "Progressing micenter.lt_en_living-in-lithuania.html (65)\n",
      "Progressing micenter.lt_en_work-in-lithuania.html (66)\n",
      "Progressing micenter.lt_en_psychological-counselling.html (67)\n",
      "Progressing micenter.lt_en_orientation-courses.html (68)\n",
      "Progressing micenter.lt_en_legal-advice.html (69)\n",
      "Progress: 30% (69/228)\n",
      "Progressing micenter.lt_en_group-therapies.html (70)\n",
      "Progressing micenter.lt_lt_lietuviu-kalbos-mokymasis.html (71)\n",
      "Progressing micenter.lt_lt_apie-mus.html (72)\n",
      "Progressing micenter.lt_lt_pagrindine-informacija.html (73)\n",
      "Progressing micenter.lt_lt_idomus-faktai.html (74)\n",
      "Progressing micenter.lt_lt_migracijos-statistika.html (75)\n",
      "Progressing micenter.lt_lt_atvykimas-i-lietuva.html (76)\n",
      "Progressing micenter.lt_lt_sengeno-viza.html (77)\n",
      "Progressing micenter.lt_lt_viza-d.html (78)\n",
      "Progressing micenter.lt_lt_leidimas-laikinai-gyventi.html (79)\n",
      "Progressing micenter.lt_lt_melynoji-kortele.html (80)\n",
      "Progressing micenter.lt_lt_leidimas-nuolat-gyventi.html (81)\n",
      "Progressing micenter.lt_lt_laikinoji-apsauga.html (82)\n",
      "Progressing micenter.lt_lt_atvykstantiems-is-ukrainos.html (83)\n",
      "Progressing micenter.lt_lt_dokumentu-legalizavimas.html (84)\n",
      "Progressing micenter.lt_lt_darbo-paieska.html (85)\n",
      "Progressing micenter.lt_lt_darbo-salygos.html (86)\n",
      "Progressing micenter.lt_lt_leidimas-dirbti.html (87)\n",
      "Progressing micenter.lt_lt_darbdavio-keitimas.html (88)\n",
      "Progressing micenter.lt_lt_verslo-pradzia.html (89)\n",
      "Progressing micenter.lt_lt_darbuotoju-teisiu-pazeidimai.html (90)\n",
      "Progressing micenter.lt_lt_gyvenamosios-vietos-deklaravimas.html (91)\n",
      "Progressing micenter.lt_lt_busto-nuoma.html (92)\n",
      "Progress: 40% (92/228)\n",
      "Progressing micenter.lt_lt_busto-pirkimas.html (93)\n",
      "Progressing micenter.lt_lt_busto-paskola.html (94)\n",
      "Progressing micenter.lt_lt_sveikatos-prieziuros-sistema.html (95)\n",
      "Progressing micenter.lt_lt_sveikatos-draudimas.html (96)\n",
      "Progressing micenter.lt_lt_gydytojai.html (97)\n",
      "Progressing micenter.lt_lt_ligonines-ir-klinikos.html (98)\n",
      "Progressing micenter.lt_lt_psichologine-pagalba.html (99)\n",
      "Progressing micenter.lt_lt_darzeliai-ir-priesmokyklinis-ugdymas.html (100)\n",
      "Progressing micenter.lt_lt_mokyklos.html (101)\n",
      "Progressing micenter.lt_lt_studijos.html (102)\n",
      "Progressing micenter.lt_lt_uzsienyje-igyti-diplomai.html (103)\n",
      "Progressing micenter.lt_lt_mokesciai.html (104)\n",
      "Progressing micenter.lt_lt_banko-saskaitos-atidarymas.html (105)\n",
      "Progressing micenter.lt_lt_paskolos.html (106)\n",
      "Progressing micenter.lt_lt_pajamu-deklaravimas.html (107)\n",
      "Progressing micenter.lt_lt_mokesciu-grazinimas.html (108)\n",
      "Progressing micenter.lt_lt_atvykimo-ismoka.html (109)\n",
      "Progressing micenter.lt_lt_ismokos-tevams.html (110)\n",
      "Progressing micenter.lt_lt_ismokos-vaikams.html (111)\n",
      "Progressing micenter.lt_lt_ligos-ir-nedarbo-ismokos.html (112)\n",
      "Progressing micenter.lt_lt_senatves-pensijos.html (113)\n",
      "Progressing micenter.lt_lt_humanitarine-pagalba.html (114)\n",
      "Progress: 50% (114/228)\n",
      "Progressing micenter.lt_lt_vaikai.html (115)\n",
      "Progressing micenter.lt_lt_santuoka.html (116)\n",
      "Progressing micenter.lt_lt_skyrybos.html (117)\n",
      "Progressing micenter.lt_lt_dviguba-pilietybe.html (118)\n",
      "Progressing micenter.lt_lt_lietuvos-pilietybe.html (119)\n",
      "Progressing micenter.lt_lt_vairuotojo-pazymejimas.html (120)\n",
      "Progressing micenter.lt_lt_vairavimo-egzaminai.html (121)\n",
      "Progressing micenter.lt_lt_transporto-priemones-registracija.html (122)\n",
      "Progressing micenter.lt_lt_automobilio-pirkimas.html (123)\n",
      "Progressing micenter.lt_lt_viesasis-transportas.html (124)\n",
      "Progressing micenter.lt_lt_el-paslaugos.html (125)\n",
      "Progressing micenter.lt_lt_apsipirkimas.html (126)\n",
      "Progressing micenter.lt_lt_telekomunikacija.html (127)\n",
      "Progressing micenter.lt_lt_komunaliniai-mokesciai.html (128)\n",
      "Progressing micenter.lt_lt_ka-daryti-nelaimes-atveju.html (129)\n",
      "Progressing micenter.lt_lt_rinkimai.html (130)\n",
      "Progressing micenter.lt_lt_kaip-tapti-vietiniu.html (131)\n",
      "Progressing micenter.lt_lt_gyvenimas-lietuvoje.html (132)\n",
      "Progressing micenter.lt_lt_karjeros-konsultacijos.html (133)\n",
      "Progressing micenter.lt_lt_psichologo-konsultacijos.html (134)\n",
      "Progressing micenter.lt_lt_kursai-apie-lietuva.html (135)\n",
      "Progressing micenter.lt_lt_teisine-pagalba.html (136)\n",
      "Progressing micenter.lt_lt_grupines-terapijos.html (137)\n",
      "Progress: 60% (137/228)\n",
      "Progressing micenter.lt_ru_izuchenie-litovskogo-yazyka.html (138)\n",
      "Progressing micenter.lt_ru_o-nas.html (139)\n",
      "Progressing micenter.lt_ru_osnovnaya-informatsiya.html (140)\n",
      "Progressing micenter.lt_ru_interesnye-fakty.html (141)\n",
      "Progressing micenter.lt_ru_statistika-po-migratsii.html (142)\n",
      "Progressing micenter.lt_ru_vezd-v-litvu.html (143)\n",
      "Progressing micenter.lt_ru_shengenskaya-viza.html (144)\n",
      "Progressing micenter.lt_ru_biza-d.html (145)\n",
      "Progressing micenter.lt_ru_vremennyi-vid-na-zhitelstvo.html (146)\n",
      "Progressing micenter.lt_ru_golubaya-karta-blue-card.html (147)\n",
      "Progressing micenter.lt_ru_postoyannyi-vid-na-zhitelstvo.html (148)\n",
      "Progressing micenter.lt_ru_vremennaya-zashchita.html (149)\n",
      "Progressing micenter.lt_ru_pribyvayushchim-iz-ukrainy.html (150)\n",
      "Progressing micenter.lt_ru_legalizatsiya-dokumentov.html (151)\n",
      "Progressing micenter.lt_ru_poisk-raboty.html (152)\n",
      "Progressing micenter.lt_ru_usloviya-truda.html (153)\n",
      "Progressing micenter.lt_ru_razreshenie-na-rabotu.html (154)\n",
      "Progressing micenter.lt_ru_smena-rabotodatelya.html (155)\n",
      "Progressing micenter.lt_ru_nachalo-biznesa.html (156)\n",
      "Progressing micenter.lt_ru_narusheniya-prav-rabotnikov.html (157)\n",
      "Progressing micenter.lt_ru_deklarirovanie-mesta-zhitelstva.html (158)\n",
      "Progressing micenter.lt_ru_arenda-zhilya.html (159)\n",
      "Progressing micenter.lt_ru_pokupka-nedvizhimosti.html (160)\n",
      "Progress: 70% (160/228)\n",
      "Progressing micenter.lt_ru_ipoteka.html (161)\n",
      "Progressing micenter.lt_ru_sistema-zdravookhraneniya.html (162)\n",
      "Progressing micenter.lt_ru_meditsinskoe-strakhovanie.html (163)\n",
      "Progressing micenter.lt_ru_vrachi.html (164)\n",
      "Progressing micenter.lt_ru_kliniki-i-bolnitsy.html (165)\n",
      "Progressing micenter.lt_ru_psikhologicheskaya-pomoshch.html (166)\n",
      "Progressing micenter.lt_ru_doshkolnoe-obrazovanie.html (167)\n",
      "Progressing micenter.lt_ru_shkoly.html (168)\n",
      "Progressing micenter.lt_ru_vysshee-obrazovanie.html (169)\n",
      "Progressing micenter.lt_ru_priznanie-obrazovaniya.html (170)\n",
      "Progressing micenter.lt_ru_nalogi.html (171)\n",
      "Progressing micenter.lt_ru_otkrytie-bankovskogo-scheta.html (172)\n",
      "Progressing micenter.lt_ru_kredity.html (173)\n",
      "Progressing micenter.lt_ru_deklaratsiya-dokhodov.html (174)\n",
      "Progressing micenter.lt_ru_vozvrat-nalogov.html (175)\n",
      "Progressing micenter.lt_ru_vyplata-po-pribytiyu.html (176)\n",
      "Progressing micenter.lt_ru_semeinye-posobiya.html (177)\n",
      "Progressing micenter.lt_ru_posobiya-na-detei.html (178)\n",
      "Progressing micenter.lt_ru_posobiya-po-bolezni-i-bezrabotitse.html (179)\n",
      "Progressing micenter.lt_ru_pensiya-po-starosti.html (180)\n",
      "Progressing micenter.lt_ru_gumanitarnaya-pomoshch.html (181)\n",
      "Progressing micenter.lt_ru_deti.html (182)\n",
      "Progressing micenter.lt_ru_registratsiya-braka.html (183)\n",
      "Progress: 80% (183/228)\n",
      "Progressing micenter.lt_ru_razvod.html (184)\n",
      "Progressing micenter.lt_ru_grazhdanstvo-litvy.html (185)\n",
      "Progressing micenter.lt_ru_dvoinoe-grazhdanstvo.html (186)\n",
      "Progressing micenter.lt_ru_voditelskie-prava.html (187)\n",
      "Progressing micenter.lt_ru_ekzameny-po-vozhdeniyu.html (188)\n",
      "Progressing micenter.lt_ru_registratsiya-avtomobilya.html (189)\n",
      "Progressing micenter.lt_ru_pokupka-avtomobilya.html (190)\n",
      "Progressing micenter.lt_ru_obshchestvennyi-transport.html (191)\n",
      "Progressing micenter.lt_ru_eluslugi.html (192)\n",
      "Progressing micenter.lt_ru_shoping.html (193)\n",
      "Progressing micenter.lt_ru_telekommunikatsii.html (194)\n",
      "Progressing micenter.lt_ru_scheta.html (195)\n",
      "Progressing micenter.lt_ru_chto-delat-v-sluchae-chrezvychainoi-situatsii.html (196)\n",
      "Progressing micenter.lt_ru_vybory.html (197)\n",
      "Progressing micenter.lt_ru_kak-stat-mestnym.html (198)\n",
      "Progressing micenter.lt_ru_zhizn-v-litve.html (199)\n",
      "Progressing micenter.lt_ru_rabota-v-litve.html (200)\n",
      "Progressing micenter.lt_ru_psikhologicheskoe-konsultirovanie.html (201)\n",
      "Progressing micenter.lt_ru_orientatsionnye-kursy.html (202)\n",
      "Progressing micenter.lt_ru_yuridicheskaya-pomoshch.html (203)\n",
      "Progressing micenter.lt_ru_gruppovye-terapii.html (204)\n",
      "Progressing micenter.lt_en_why-learn-the-lithuanian-language.html (205)\n",
      "Progressing micenter.lt_en_legal-requirements.html (206)\n",
      "Progress: 90% (206/228)\n",
      "Progressing micenter.lt_en_exams-and-tests.html (207)\n",
      "Progressing micenter.lt_en_where-can-i-learn-lithuanian.html (208)\n",
      "Progressing micenter.lt_lt_kodel-verta-mokytis-lietuviu-kalbos.html (209)\n",
      "Progressing micenter.lt_lt_teises-aktu-reikalavimai.html (210)\n",
      "Progressing micenter.lt_lt_egzaminai-ir-testai.html (211)\n",
      "Progressing micenter.lt_lt_kur-mokytis-lietuviu-kalbos.html (212)\n",
      "Progressing micenter.lt_ru_pochemu-stoit-uchit-litovskii-yazyk.html (213)\n",
      "Progressing micenter.lt_ru_zakonodatelnye-trebovaniya.html (214)\n",
      "Progressing micenter.lt_ru_ekzameny-i-testy.html (215)\n",
      "Progressing micenter.lt_ru_gde-ya-mogu-vyuchit-litovskii-yazyk.html (216)\n",
      "Progressing micenter.lt_en_vilnius.html (217)\n",
      "Progressing micenter.lt_en_kaunas.html (218)\n",
      "Progressing micenter.lt_en_klaipeda.html (219)\n",
      "Progressing micenter.lt_en_independent-learning.html (220)\n",
      "Progressing micenter.lt_lt_mokymasis-savarankiskai.html (221)\n",
      "Progressing micenter.lt_lt_vilnius.html (222)\n",
      "Progressing micenter.lt_lt_kaunas.html (223)\n",
      "Progressing micenter.lt_lt_klaipeda.html (224)\n",
      "Progressing micenter.lt_ru_vilnyus.html (225)\n",
      "Progressing micenter.lt_ru_kaunas.html (226)\n",
      "Progressing micenter.lt_ru_klaipeda.html (227)\n",
      "Progressing micenter.lt_ru_samostoyatelnoe-obuchenie.html (228)\n",
      "Progress: 100% (228/228)\n",
      "Processed: micenter_site\n",
      "✅ Elements from all cleaned sites merged and saved to /home/gerzem1/PDP/DCIP/migrant-info-platform/backend/chatbot_service/data/cleaned/sites_elements.json\n"
     ]
    }
   ],
   "source": [
    "config_all_sites_data = {\n",
    "    \"ALLOWED_TAGS\": ALLOWED_TAGS,\n",
    "    \"RAW_DATA_DIR\": RAW_DATA_DIR,\n",
    "    \"CLEANED_DATA_DIR\": CLEANED_DATA_DIR,\n",
    "    \"URL_MAP_FILENAME\": URL_MAP_FILENAME,\n",
    "    \"SITE_ELEMENTS_JSON_FILENAME\": SITE_ELEMENTS_JSON_FILENAME,\n",
    "    \"SITES_ELEMENTS_JSON_PATH\": SITES_ELEMENTS_JSON_PATH,\n",
    "    \"SIMILAR_TEXT_THRESHOLD\": SIMILAR_TEXT_THRESHOLD\n",
    "}\n",
    "\n",
    "all_sites_data_handler = AllCleanedSitesData(sites_dirs=SITES_DIRS, config=config_all_sites_data)\n",
    "sites_data = all_sites_data_handler.convert_sites_data_to_json_list()\n",
    "print(f\"✅ Elements from all cleaned sites merged and saved to {SITES_ELEMENTS_JSON_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cb7e3f-ef95-4b59-8bc2-c6ba71c1d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_html_cleaner = {\n",
    "#     \"allowed_tags\": ALLOWED_TAGS,\n",
    "#     \"debug\": True\n",
    "# }\n",
    "\n",
    "# for site_dir in SITES_DIRS:\n",
    "#     url_map_path = os.path.join(RAW_DATA_DIR, site_dir, URL_MAP_FILENAME)\n",
    "#     with open(url_map_path, 'r', encoding='utf-8') as file:\n",
    "#         url_map = json.load(file)\n",
    "\n",
    "#     # Iterate over the dict: html_filename → page_link\n",
    "#     for html_filename, page_link in url_map.items():\n",
    "#         base, extension = os.path.splitext(os.path.join(CLEANED_DATA_DIR, site_dir, html_filename))\n",
    "#         if extension != \".html\":\n",
    "#             continue       \n",
    "        \n",
    "#         html_path = os.path.join(RAW_DATA_DIR, site_dir, html_filename)\n",
    "#         if not os.path.isfile(html_path):\n",
    "#             print(f\"Warning: File not found: {html_path}\")\n",
    "#             continue\n",
    "        \n",
    "#         html_cleaner = HTMLCleaner(html_path=html_path, source_url=page_link, config=config_html_cleaner)\n",
    "        \n",
    "#         os.makedirs(os.path.join(CLEANED_DATA_DIR, site_dir), exist_ok=True) \n",
    "#         # saving_path = base + \".json\"\n",
    "#         clean_text_from_html = html_cleaner.convert_soup_to_clean_text()\n",
    "        \n",
    "        \n",
    "#     print(f\"Processed: {site_dir}\")\n",
    "\n",
    "# print(f\"Html files were converted to cleaned json array and saved to {CLEANED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "239a1d19-f364-477f-98f6-f0c5365f1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_links(text: str) -> str:\n",
    "#     # Removes [anything inside brackets]\n",
    "#     return re.sub(r\"\\[[^\\[\\]]*\\]\", \"\", text)\n",
    "\n",
    "# def normalize_for_comparison(text: str) -> str:\n",
    "#     text_no_links = remove_links(text)\n",
    "#     text_cleaned = text_no_links.lower().strip().replace('\\xa0', ' ')\n",
    "#     return ' '.join(text_cleaned.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a8ee27-d30f-4058-b281-68f36db853d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites_elements_json = []\n",
    "\n",
    "# for site_dir in SITES_DIRS:\n",
    "#     cleaned_site_dir = os.path.join(CLEANED_DATA_DIR, site_dir)\n",
    "\n",
    "#     for cleaned_file_name in os.listdir(cleaned_site_dir):\n",
    "#         cleaned_file_path = os.path.join(cleaned_site_dir, cleaned_file_name)\n",
    "#         if not os.path.isfile(cleaned_file_path):\n",
    "#             continue\n",
    "\n",
    "#         with open(cleaned_file_path, 'r', encoding='utf-8') as file:\n",
    "#             cleaned_data_set = json.load(file)\n",
    "        \n",
    "#         for new_element in cleaned_data_set:\n",
    "#             is_new_el_different = True\n",
    "#             # Check if there is no other element with the same text - redundancy is not needed\n",
    "#             for saved_element in sites_elements_json:\n",
    "                \n",
    "#                 normalized_saved = normalize_for_comparison(saved_element['text'])\n",
    "#                 normalized_new = normalize_for_comparison(new_element['text'])\n",
    "                \n",
    "#                 if SequenceMatcher(None, normalized_saved, normalized_new).ratio() > SIMILAR_TEXT_THRESHOLD:\n",
    "#                     is_new_el_different = False\n",
    "#                     break\n",
    "                    \n",
    "#                 # if new_element['text'] == saved_element['text']:\n",
    "#                 #     is_new_el_different = False\n",
    "#                 #     break\n",
    "\n",
    "#             if is_new_el_different:\n",
    "#                 sites_elements_json.append(new_element)\n",
    "\n",
    "#         if len(sites_elements_json) > 40:\n",
    "#             break\n",
    "\n",
    "                \n",
    "# # with open(SITES_ELEMENTS_JSON_PATH, \"w\", encoding=\"utf-8\") as file:\n",
    "# #     json.dump(sites_elements_json, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "# print(f\"✅ Elements from all cleaned sites merged and saved to {SITES_ELEMENTS_JSON_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ecb667e-2f89-4749-bec5-8ee9bf11d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites_elements_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466cc0f-57f9-4f9f-9e99-db2dbaf52263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
